{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interpreted-cursor",
   "metadata": {},
   "source": [
    "## Classic One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "alleged-quantity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features:  8 \n",
      "\n",
      "text_label_map:  {'hello': 0, 'bitsians': 1, 'how': 2, 'are': 3, 'you': 4, 'doing': 5, 'today': 6, '?': 7} \n",
      "\n",
      "['hello' 'bitsians' 'how' 'are' 'you' 'doing' 'today' '?'] \n",
      "\n",
      "[4 2 5 1 7 3 6 0]\n",
      "onehot_encoded shape:  (8, 8) \n",
      "\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "['hello']\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "text = 'hello bitsians how are you doing today ?'\n",
    "\n",
    "text_label_map = {}\n",
    "\n",
    "for word in text.split():\n",
    "    if word not in text_label_map:\n",
    "        text_label_map[word] = len(text_label_map)\n",
    "\n",
    "print(\"number of features: \", len(text_label_list), '\\n')\n",
    "print(\"text_label_map: \", text_label_map, '\\n')\n",
    "\n",
    "\n",
    "# define example\n",
    "data = text.split()\n",
    "values = array(data)\n",
    "print(values, '\\n')\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(\"onehot_encoded shape: \", onehot_encoded.shape, '\\n')\n",
    "print(onehot_encoded, '\\n')\n",
    "\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-alliance",
   "metadata": {},
   "source": [
    "## Quiz: What's the problem with One-Hot Encoding Approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-brown",
   "metadata": {},
   "source": [
    "## Word Embedding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "listed-swing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=14, size=30, alpha=0.025) \n",
      "\n",
      "['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec', 'second', 'yet', 'another', 'one', 'more', 'and', 'final'] \n",
      "\n",
      "[-0.00168845 -0.00108926  0.01517474 -0.00147417  0.01347492 -0.00420771\n",
      "  0.01537163  0.01103556 -0.00048048  0.0006031   0.00957203  0.00216474\n",
      "  0.00289918  0.00857945 -0.01114961  0.00740007 -0.01172909 -0.00859065\n",
      " -0.00563982  0.00953312  0.01099747  0.01123064 -0.00702224  0.00411851\n",
      " -0.00225844  0.01257167  0.0041694   0.00280735 -0.00141178 -0.01482459] \n",
      "\n",
      "Word2Vec(vocab=14, size=30, alpha=0.025) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chandra/anaconda3/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
    "\t\t\t['yet', 'another', 'sentence'],\n",
    "\t\t\t['one', 'more', 'sentence'],\n",
    "\t\t\t['and', 'the', 'final', 'sentence']]\n",
    "\n",
    "# train model\n",
    "model = Word2Vec(sentences, min_count=1, size=30)\n",
    "\n",
    "# summarize the loaded model\n",
    "print(model, '\\n')\n",
    "\n",
    "# summarize vocabulary\n",
    "words = list(model.wv.vocab)\n",
    "print(words, '\\n')\n",
    "# access vector for one word\n",
    "print(model['sentence'], '\\n')\n",
    "\n",
    "# save model\n",
    "model.save('model.bin')\n",
    "# load model\n",
    "new_model = Word2Vec.load('model.bin')\n",
    "print(new_model, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-portal",
   "metadata": {},
   "source": [
    "## Quiz: What's the problem with Word Embedding Approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-memorial",
   "metadata": {},
   "source": [
    "## Transformers: Contextual Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-system",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('nlu': conda)",
   "language": "python",
   "name": "python37964bitnluconda69b508d6e8ef4c30a74bf012806384a9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
